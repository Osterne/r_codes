#=====================================================================
#Code: Clustering via K-means algorithm
#Author: Vinicius Osterne (vinicius@osterne -- www.osterne.com)
#=====================================================================



#---------------------------------------------------------------------
# Clearing memory
#---------------------------------------------------------------------
rm(list=ls())






#---------------------------------------------------------------------
# Package necessary
#---------------------------------------------------------------------
library(philentropy)













#---------------------------------------------------------------------
# Clustering via K-means algorithm - Function construction
#---------------------------------------------------------------------

KmeansCluster = function(k, data){
  

  
# Step 1: Initial values for prototypes (random selection)
ind =  seq(1, dim(data)[1], 1)
select.ind = sample(ind, size = k, replace = F)

prot = list()
for (i in 1:k) {
  prot[[i]] = data[select.ind[i],]
}



dif = 1
while (dif > 0.01) {
  
# Step 2: Calculate distance between obs i and prototype k
N = dim(data)[1]
euclidian.distance = c()
m = list()

for (j in 1:k) {
  for (i in 1:N) {
    euclidian.distance[i] = distance(rbind(prot[[j]], data[i,]), method = "euclidean")
  }
  m[[j]] = euclidian.distance
}



# Step 3: Classify based on the shortest distance between obs i and prototype k
m.dist = Reduce(cbind, m)
m.dist = data.frame(m.dist)
names(m.dist) = seq(1,k,1)

out = c()
for (i in 1:N) {
  out[i] = names(m.dist)[which.min(m.dist[i,])]
}

new.data = data.frame(cbind(data,out))
new.data = lapply(new.data,as.numeric)
new.data = data.frame(new.data)



# Step 4: Update the prototype with the mean
prot.actual = list()
aux.k = dim(data)[2] + 1
for (i in 1:k) {
  prot.actual[[i]] = apply(subset(new.data, out == i)[-aux.k], 2, mean)
}

#prot.actual = Reduce(rbind, aux)
#prot.actual = data.frame(prot.actual)[-aux.k]





# Conditional for while
normk = c()
for (i in 1:k) {
  normk[i] = norm(as.matrix(prot[[i]] - prot.actual[[i]]))
}
dif = sum(normk)
prot = prot.actual




}#end while





# Calculating SSD measure
ssd.data = data.frame(cbind(m.dist,out))
SSDk = c()
for (i in 1:k) {
  SSDk[i] = sum(subset(ssd.data, out == i)[,i])
}
SSD = sum(SSDk)


# Calculating Dunn index:
library(clValid)
forIndex = as.numeric(out)
dunnIndex = dunn(clusters = forIndex, Data=data)



# Calculating Davies-Bouldin index:
library(clusterSim)
dbIndex = index.DB(data, forIndex, centrotypes="centroids")$DB



# Calculating Calinski-Harabasz index:
library(fpc)
chIndex = calinhara(data, forIndex)




# Outpusts for function
mylist = list("ssd" = SSD, "prot.values" = prot, "dunnIndex" = dunnIndex,  "dbIndex" = dbIndex, "chIndex" = chIndex)
return(mylist)

}